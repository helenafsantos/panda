#!/usr/bin/env python

"""Script to retreve datasets (input or output) in submitted jobs

With a specified search string, will search for datasets with that
name. If the name doesn't end in `*` or `/`, append a wildcard.
if the string is '-', the datasets are read from stdin.

The user name can be specified via environment variable to reduce
clutter.

"""
# help strings
_h_taskname='initial search string'
_h_user='full user name, or blank for all'
_h_stream='stream name fragment to filter for'
_h_days='only look back this many days'
_h_state='prefix dataset name with state'
_h_clean='clean output: better for cut or grep'
_h_taskid='output only taskid. useful for piping.'
_h_print_browser_string = (
    'don\'t run query, just print string to copy into browser')
_h_print_json_reply = (
    'don\'t format output, just print the json reply from the server')
_h_force_update = 'don\'t allow caching on the server, (force with timestamp)'
# defaults
_def_user='GRID_USER_NAME'
_def_stream='OUT'

import urllib2
import urllib
import json
import sys, os
import re
import argparse
import datetime

_headers = {'Accept': 'application/json',
            'Content-Type':'application/json',
            'User-Agent':'User-Agent: curl/7.43.0'}

def get_args():
    d = ' (default: %(default)s)'
    c = ' (default: %(const)s)'
    user=os.environ.get(_def_user, '')
    if not user:
        de = ' (please set {} environment variable)'.format(_def_user)
    else:
        de = d
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter)
    userenv = 'RUCIO_ACCOUNT' if 'RUCIO_ACCOUNT' in os.environ else 'USER'
    parser.add_argument('taskname', help=_h_taskname, nargs='?',
                        default="user.{}".format(os.environ[userenv]) )
    parser.add_argument('-u','--user', help=_h_user + de, default=user)
    parser.add_argument('-d','--days', help=_h_days, type=int)
    addinfo = parser.add_mutually_exclusive_group()
    addinfo.add_argument('-s','--stream', help=_h_stream + c, nargs='?',
                         default=None, const=_def_stream)
    parser.add_argument('-c','--clean', action='store_true', help=_h_clean)
    parser.add_argument('-t','--taskid', action='store_true', help=_h_taskid)
    output = parser.add_mutually_exclusive_group()
    output.add_argument('-b','--print-browser-string', action='store_true',
                        help=_h_print_browser_string)
    output.add_argument('-j','--print-json-reply', action='store_true',
                        help=_h_print_json_reply)

    parser.add_argument('-f','--force', action='store_true',
                        help=_h_force_update)

    args = parser.parse_args()
    if not args.taskname and sys.stdin.isatty():
        parser.print_usage()
        sys.exit('ERROR: need to pipe datasets or specify a search string')
    return args

def get_request(taskname, user, days=None, json=True, force=False):
    pars = {
        'taskname': taskname,
        'username': user,
    }
    if json:
        pars['json'] = 1
    if force:
        pars['timestamp'] = datetime.datetime.utcnow().strftime('%H:%M:%S')
    if days is not None:
        pars['days'] = days
    url = 'http://bigpanda.cern.ch/tasks/?' + urllib.urlencode(pars)
    return urllib2.Request(url, headers=_headers)

def get_ds(taskid, streamfrag, days=None):
    pars = {
        'jeditaskid': taskid,
        'datasets': True,
        'json': True
    }
    if days is not None:
        pars['days'] = days
    url = 'http://bigpanda.cern.ch/tasks/?' + urllib.urlencode(pars)
    req = urllib2.Request(url, headers=_headers)
    stuff = urllib2.urlopen(req).read().decode('utf-8')
    # containers = set()
    for entry in json.loads(stuff):
        datasets = entry['datasets']
        streams = {ds['streamname']: ds for ds in datasets}
        for stream, ds in streams.items():
            if streamfrag.upper() in stream:
                yield streams[stream]['containername']


RED = '\033[0;91m'
GREEN = '\033[92m'
YELLOW = '\033[93m'
BLUE = '\033[94m'
MAGENTA = '\033[95m'
CYAN = '\033[96m'
ENDC = '\033[0m'
BOLD = '\033[1m'
UNDERLINE = '\033[4m'
BLINK = '\033[5m'

_color_dic = {
    'running': BLUE + BOLD,
    'submitting': CYAN,
    'registered': MAGENTA,
    'ready': MAGENTA,
    'done': GREEN,
    'finished': YELLOW,
    'broken': RED + BOLD,
    'aborted': RED,
    'failed': RED,
    }
def getstatus(task, args):
    if args.clean:
        fmt_string = '{s} {i} {p:.0%} {t} '
    elif args.taskid:
        fmt_string = '{i}'
    else:
        fmt_string = '{s:<{l}} {i:<9} {p: <6.0%} {t} '
    if sys.stdout.isatty() and not args.clean:
        color = _color_dic.get(task['superstatus'], ENDC)
        status_color = color + task['status'] + ENDC
        nonprlen = len(color) + len(ENDC)
    else:
        status_color = task['status']
        nonprlen = 0

    if not args.taskid:
        outputString = fmt_string.format(
            s=status_color, t=task['taskname'], i=task['reqid'],
            l=(11 + nonprlen), p=task['dsinfo']["pctfinished"]/100.0)
    if args.taskid:
        outputString = fmt_string.format( i=task['reqid'] )

    return outputString

def stdin_iter(args):
    for line in sys.stdin:
        task = line.strip()
        if task[-1] not in '/*':
            task = task + '*'
        req = get_request(task, args.user, args.days)
        for ds in json.loads(urllib2.urlopen(req).read().decode('utf-8')):
            yield ds

def run():
    args = get_args()

    taskname = args.taskname
    # try to search
    if taskname != '-':
        # append a wildcard if I forgot
        if args.taskname[-1] not in '/*':
            taskname = taskname + '*'
        use_json = not args.print_browser_string
        req = get_request(taskname, args.user, args.days, use_json, args.force)
        if args.print_browser_string:
            sys.stdout.write(req.get_full_url() + '\n')
            return 0
        reply = urllib2.urlopen(req).read().decode('utf-8')
        if args.print_json_reply:
            sys.stdout.write(reply)
            return 0
        datasets = json.loads(reply)
    else:
        # otherwise read from stdin
        datasets = stdin_iter(args)

    # loop over tasks
    for task in datasets:
        if args.stream:
            for ds in get_ds(task['jeditaskid'], args.stream, days=args.days):
                sys.stdout.write(ds + '\n')
        else:
            sys.stdout.write(getstatus(task, args) + '\n')


if __name__ == '__main__':
    run()
